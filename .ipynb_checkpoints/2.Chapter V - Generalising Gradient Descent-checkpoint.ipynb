{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent With Multiple Inputs ###\n",
    "In the previous chapter, we have used gradient descent to update the weight of a simple network with a single weight and single input. We will now show how the same tecnhique can be used in the case of networks with multiple inputs/weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.5, 0.65, 1.2]\n",
      "Error: 0.01959999999999997, Delta: -0.1399999999999999\n",
      "[-1.189999999999999, -0.09099999999999994, -0.16799999999999987]\n"
     ]
    }
   ],
   "source": [
    "def w_sum(a,b):\n",
    "    assert(len(a) == len(b))\n",
    "    output = 0\n",
    "    for i in range(len(a)):\n",
    "        output += a[i] * b[i]\n",
    "    return output\n",
    "\n",
    "def ele_mul(number, vector):\n",
    "    \"\"\" multiplies all the elements of a @vector with a @number\"\"\"\n",
    "    output = [number*elem for elem in vector]\n",
    "    return output\n",
    "\n",
    "weights = [0.1, 0.2, -.1]\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    pred = w_sum(input, weights)\n",
    "    return pred\n",
    "\n",
    "# These are our features\n",
    "toes = [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "# These are our observed wins/loses that eventually will be predicted\n",
    "win_or_lose_binary = [1, 1, 0, 1]\n",
    "\n",
    "# Create the first input vector:\n",
    "input = [toes[0], wlrec[0], nfans[0]]\n",
    "print(input)\n",
    "# Get the first label\n",
    "true = win_or_lose_binary[0]\n",
    "\n",
    "pred = neural_network(input, weights)\n",
    "error = (pred - true) ** 2\n",
    "delta = pred - true\n",
    "\n",
    "# We still multiply the (pred - true) * input as before. The only difference\n",
    "# is that now input is a vector and as a result weight_deltas is also a vector:\n",
    "weight_deltas = ele_mul(delta, input)\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "for i in range(len(weights)):\n",
    "    weights[i] -= alpha * weight_deltas[i]\n",
    "print(\"Error: {}, Delta: {}\".format(error, delta))\n",
    "print(weight_deltas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One might wonder why the above update rule works. Why is it ok to use the single delta multiplied by the input-vector to get the  weight_deltas vector? <br>\n",
    "Well, the answer is clear if we calculate the partial derivatives of the error w.r.t each weight. It is evident then that the partial derivative of each weight is nothing more but the (SAME) delta value multiplied by the input value of each weight! <br><br>\n",
    "Below are the graphs of the error plotted against each weight (with the other two weights kept constant <- partial derivative):\n",
    "<img src=\"images/7.Gradient_Descent_Multiple_weights.PNG\">\n",
    "Notice that the error graph of weight1 is much steeper than the rest. This is because although all have the same delta, the first weight has a much larger input value. This actually forced us to keep the alpha lower than 0.1 to 0.01 otherwise the first weight does not converge. Also, large input values mean that some inputs/weights do the most learning and the rest are pretty much ignored since they contribute little to the final error. This is few of the reasons why all inputs should be normalised before we run them through the network.\n",
    "\n",
    "<br>\n",
    "Now, lets modify the code above to watch several steps of learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 0:\n",
      "\n",
      "Prediction: 0.9338317682295959, Error: 0.004378234895621914\n",
      "Updated Weights: [0.11507515561204433, 0.19813606143916426, -0.10338046969783081]\n",
      "------------------------\n",
      "\n",
      "At iteration 1:\n",
      "\n",
      "Prediction: 0.9828706990004368, Error: 0.00029341295273363764\n",
      "Updated Weights: [0.1165311461970072, 0.19824740189566142, -0.10317491808583605]\n",
      "------------------------\n",
      "\n",
      "At iteration 2:\n",
      "\n",
      "Prediction: 0.9955656522037379, Error: 1.9663440378214202e-05\n",
      "Updated Weights: [0.11690806575968948, 0.19827622515633714, -0.10312170591228091]\n",
      "------------------------\n",
      "\n",
      "At iteration 3:\n",
      "\n",
      "Prediction: 0.9988520582142426, Error: 1.3177703434878639e-06\n",
      "Updated Weights: [0.11700564081147886, 0.19828368677794456, -0.10310793061085183]\n",
      "------------------------\n",
      "\n",
      "At iteration 4:\n",
      "\n",
      "Prediction: 0.9997028265702121, Error: 8.831204737187771e-08\n",
      "Updated Weights: [0.11703090055301084, 0.19828561840523817, -0.10310436452969438]\n",
      "------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.01\n",
    "\n",
    "for i in range(5):\n",
    "    pred = neural_network(input, weights)\n",
    "    error = (pred - true) ** 2\n",
    "    delta = (pred - true)\n",
    "    \n",
    "    weight_deltas = ele_mul(delta, input)\n",
    "    \n",
    "    for j in range(len(weights)):\n",
    "        weights[j] -= alpha * weight_deltas[j]\n",
    "        \n",
    "    print(\"At iteration {}:\\n\".format(i))\n",
    "    print(\"Prediction: {}, Error: {}\".format(pred, error))\n",
    "    print(\"Updated Weights: {}\".format(weights))\n",
    "    print(\"------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Learning with Multiple Outputs ###\n",
    "We will now consider the case where multiple predictions. are made from a single input value.<br>\n",
    "Consider the network:\n",
    "<img src=\"images/8.Gradient_Descent_Multiple_predictions.PNG\">\n",
    "\n",
    "The main difference is that now, we have 3 errors and 3 deltas instead of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iteration 0:\n",
      "Prediction: [0.27, 0.18000000000000002, 0.81]\n",
      "Deltas: [0.17, -0.82, 0.7100000000000001]\n",
      "Error: [0.028900000000000006, 0.6723999999999999, 0.5041000000000001]\n",
      "Weights: [0.2847, 0.27380000000000004, 0.8361000000000001]\n",
      "---------------------\n",
      "\n",
      "At iteration 1:\n",
      "Prediction: [0.25623, 0.24642000000000006, 0.7524900000000001]\n",
      "Deltas: [0.15623, -0.7535799999999999, 0.6524900000000001]\n",
      "Error: [0.024407812900000003, 0.5678828163999998, 0.42574320010000016]\n",
      "Weights: [0.2706393, 0.34162220000000004, 0.7773759]\n",
      "---------------------\n",
      "\n",
      "At iteration 2:\n",
      "Prediction: [0.24357537000000004, 0.30745998, 0.69963831]\n",
      "Deltas: [0.14357537000000004, -0.69254002, 0.59963831]\n",
      "Error: [0.02061388687063691, 0.4796116793016004, 0.3595661028196561]\n",
      "Weights: [0.25771751670000004, 0.40395080180000004, 0.7234084521]\n",
      "---------------------\n",
      "\n",
      "At iteration 3:\n",
      "Prediction: [0.23194576503000003, 0.36355572162000005, 0.6510676068900001]\n",
      "Deltas: [0.13194576503000002, -0.63644427838, 0.5510676068900001]\n",
      "Error: [0.017409684909351977, 0.40506131948263885, 0.3036755073634717]\n",
      "Weights: [0.24584239784730003, 0.46123078685420005, 0.6738123674799]\n",
      "---------------------\n",
      "\n",
      "At iteration 4:\n",
      "Prediction: [0.22125815806257002, 0.41510770816878007, 0.60643113073191]\n",
      "Deltas: [0.12125815806257001, -0.5848922918312199, 0.50643113073191]\n",
      "Error: [0.014703540896727213, 0.34209899304357694, 0.25647249017440094]\n",
      "Weights: [0.2349291636216687, 0.5138710931190098, 0.6282335657140281]\n",
      "---------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def neural_network(input, weights):\n",
    "    # Now we use the ele_mul function as we want the result\n",
    "    # to be vector instead of a single value: \n",
    "    pred = ele_mul(input, weights)\n",
    "    return pred\n",
    "\n",
    "# Define the weights\n",
    "weights = [0.3, 0.2, 0.9] \n",
    "alpha = 0.1\n",
    "\n",
    "# input-vector:\n",
    "wlrec = [0.9, 1.0, 1.0, 0.9]\n",
    "\n",
    "# now we have 3 label-vectors:\n",
    "hurt = [0.1, 0.0, 0.0, 0.1]\n",
    "win = [ 1, 1, 0, 1]\n",
    "sad = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "# First observation is now a value instead of a vector:\n",
    "input = wlrec[0]\n",
    "\n",
    "# This is now a vector instead of a single value\n",
    "true = [hurt[0], win[0], sad[0]]\n",
    "\n",
    "\n",
    "error = [0, 0, 0]\n",
    "delta = [0, 0, 0]\n",
    "\n",
    "weight_deltas = [0, 0, 0]\n",
    "\n",
    "for iter in range(5):\n",
    "    \n",
    "    pred = neural_network(input,weights)\n",
    "    for i in range(len(pred)):\n",
    "        error[i] = (pred[i] - true[i]) ** 2\n",
    "        delta[i] = pred[i] - true[i]\n",
    "        weight_deltas[i] = delta[i] * input\n",
    "\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= alpha*weight_deltas[i]\n",
    "    \n",
    "    print(\"At iteration {}:\".format(iter))\n",
    "    print(\"Prediction: {}\".format(pred))\n",
    "    print(\"Deltas: {}\".format(delta))\n",
    "    print(\"Error: {}\".format(error))\n",
    "\n",
    "    print(\"Weights: {}\".format(weights))\n",
    "    print(\"---------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent with Multiple Inputs & Outputs ###\n",
    "Combining the previous two examples we can now create the following architecture:\n",
    "<img src=\"images/9.Gradient_Descent_Multiple_Input_Output.PNG\">\n",
    "\n",
    "Now, both the input to the network and the output are vectors. This means that the weights of the network must be a matrix. The matrix is constructed in such way so that each row corresponds to the 3 input values going into each output node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5800000000000001, 1.03, 1.29]\n",
      "[8.5, 0.9, 1.2]\n"
     ]
    }
   ],
   "source": [
    "def vect_mat_mul(a,b):\n",
    "    assert(len(a)==len(b))\n",
    "    output = [0 for elem in a]\n",
    "    for i in range(len(a)):\n",
    "        output[i] = w_sum(a, b[i])\n",
    "    \n",
    "    return output \n",
    "toes = [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65,0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "hurt = [0.1, 0.0, 0.0, 0.1]\n",
    "win = [ 1, 1, 0, 1]\n",
    "sad = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "weights = [  [0.1, 0.1, -0.3],#hurt?\n",
    "             [0.1, 0.2, 0.0], #win?\n",
    "             [0.0, 1.3, 0.1] ]#sad?\n",
    "\n",
    "input = [toes[0],wlrec[0],nfans[0]]\n",
    "\n",
    "print(vect_mat_mul(input, weights))\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
