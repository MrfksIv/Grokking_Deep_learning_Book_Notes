{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting revisited ###\n",
    "We have previously shown that by using a middle layer our network was able to create \"intermediate\" correlation. This actually made learning (or more mundanely error minimisation) possible. <br>\n",
    "__Although adding more layers (or neurons at each layer) increases the networks expressiveness, it also increases the risk of overfitting__.\n",
    "The next step is to talk about regularisation, one of the main tools to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import MNIST_Attempt.image_utils as iu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in file: 10000\n",
      "Total labels in file: 10000\n",
      "Total images in file: 60000\n",
      "Total labels in file: 60000\n"
     ]
    }
   ],
   "source": [
    "# import the mnist data:\n",
    "\n",
    "test_data_file= \"t10k-images.idx3-ubyte\"\n",
    "test_labels_file = \"t10k-labels.idx1-ubyte\"\n",
    "\n",
    "training_data_file = \"train-images.idx3-ubyte\"\n",
    "training_labels_file = \"train-labels.idx1-ubyte\"\n",
    "\n",
    "test_data = iu.load_image_file(\"MNIST_Attempt/data\", test_data_file)\n",
    "test_labels = iu.load_labels_file(\"MNIST_Attempt/data\", test_labels_file)\n",
    "\n",
    "training_data = iu.load_image_file(\"MNIST_Attempt/data\", training_data_file)\n",
    "training_labels = iu.load_labels_file(\"MNIST_Attempt/data\", training_labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the activation function and its derivative:\n",
    "def relu(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "def relu_deriv(x):\n",
    "    return x > 0\n",
    "\n",
    "def one_hot_encode(np_arr):\n",
    "    return np.eye(np.max(np_arr) + 1)[np_arr.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_labels = one_hot_encode(training_labels)\n",
    "test_labels = one_hot_encode(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the network's hyperparameters:\n",
    "alpha = 0.005\n",
    "epochs = 100\n",
    "\n",
    "input_layer_size = training_data.shape[1] # 784 \n",
    "hidden_layer_size = 100 \n",
    "output_layer_size = 10\n",
    "\n",
    "# Normalise the image data:\n",
    "training_data_norm = (training_data - 128) / 128\n",
    "test_data_norm = (test_data - 128) / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.625, Error:0.4157463074591412\n",
      "Accuracy: 0.785, Error:0.3540538022001188\n",
      "Accuracy: 0.838, Error:0.2830472224002628\n",
      "Accuracy: 0.866, Error:0.25530557290898764\n",
      "Accuracy: 0.889, Error:0.22286178560863248\n",
      "Accuracy: 0.908, Error:0.1938857846655671\n",
      "Accuracy: 0.922, Error:0.16916906972638163\n",
      "Accuracy: 0.938, Error:0.14857874423530387\n",
      "Accuracy: 0.943, Error:0.13000050315385672\n",
      "Accuracy: 0.951, Error:0.10274531621452632\n",
      "Accuracy: 0.954, Error:0.09315652271520697\n",
      "Accuracy: 0.961, Error:0.07324297150136856\n",
      "Accuracy: 0.962, Error:0.06059672089677537\n",
      "Accuracy: 0.966, Error:0.04911458373123536\n",
      "Accuracy: 0.968, Error:0.03830243792759229\n",
      "Accuracy: 0.972, Error:0.03200202765188133\n",
      "Accuracy: 0.976, Error:0.03156054995661453\n",
      "Accuracy: 0.98, Error:0.027624832602849456\n",
      "Accuracy: 0.982, Error:0.023467741419800802\n",
      "Accuracy: 0.983, Error:0.021765418769072523\n",
      "Accuracy: 0.983, Error:0.02137737968980616\n",
      "Accuracy: 0.985, Error:0.018821317296111473\n",
      "Accuracy: 0.987, Error:0.01959784756702774\n",
      "Accuracy: 0.988, Error:0.018509562581264318\n",
      "Accuracy: 0.99, Error:0.01692376225876415\n",
      "Accuracy: 0.992, Error:0.013401339380218523\n",
      "Accuracy: 0.991, Error:0.01481084499608778\n",
      "Accuracy: 0.991, Error:0.01506127972654399\n",
      "Accuracy: 0.991, Error:0.012327986618659834\n",
      "Accuracy: 0.991, Error:0.013553023150984242\n",
      "Accuracy: 0.992, Error:0.01240792313579851\n",
      "Accuracy: 0.992, Error:0.013783005032081744\n",
      "Accuracy: 0.993, Error:0.0144511551978267\n",
      "Accuracy: 0.995, Error:0.016088383495290633\n",
      "Accuracy: 0.996, Error:0.014737822942385934\n",
      "Accuracy: 0.996, Error:0.01691974975619672\n",
      "Accuracy: 0.996, Error:0.017770297935412346\n",
      "Accuracy: 0.997, Error:0.019779489661534803\n",
      "Accuracy: 0.997, Error:0.018253013710596275\n",
      "Accuracy: 0.997, Error:0.02150121179965087\n",
      "Accuracy: 0.998, Error:0.02026313611407511\n",
      "Accuracy: 0.997, Error:0.02082085888352327\n",
      "Accuracy: 0.998, Error:0.02121771197137397\n",
      "Accuracy: 0.998, Error:0.020625607259154126\n",
      "Accuracy: 0.998, Error:0.020657845591687964\n",
      "Accuracy: 0.998, Error:0.02045692911123356\n",
      "Accuracy: 0.998, Error:0.022047895016979617\n",
      "Accuracy: 0.998, Error:0.0201820655300397\n",
      "Accuracy: 0.999, Error:0.021723797847144004\n",
      "Accuracy: 0.999, Error:0.021322640561544932\n",
      "Accuracy: 0.999, Error:0.018856823691986258\n",
      "Accuracy: 0.999, Error:0.01953625367490543\n",
      "Accuracy: 0.999, Error:0.018553132262104956\n",
      "Accuracy: 0.999, Error:0.017889369019582182\n",
      "Accuracy: 0.999, Error:0.01709947121562421\n",
      "Accuracy: 0.998, Error:0.017262446561284332\n",
      "Accuracy: 0.998, Error:0.01653931722214204\n",
      "Accuracy: 0.998, Error:0.01592264526609649\n",
      "Accuracy: 0.998, Error:0.016050866111958658\n",
      "Accuracy: 0.998, Error:0.01511286069322269\n",
      "Accuracy: 0.998, Error:0.015812646766609113\n",
      "Accuracy: 0.998, Error:0.01603505982651585\n",
      "Accuracy: 0.999, Error:0.015946164108042407\n",
      "Accuracy: 0.999, Error:0.014792654442647973\n",
      "Accuracy: 0.999, Error:0.014937489162778815\n",
      "Accuracy: 0.999, Error:0.01473678100870567\n",
      "Accuracy: 0.999, Error:0.014842015995371296\n",
      "Accuracy: 0.999, Error:0.014950108828162419\n",
      "Accuracy: 0.999, Error:0.014321971886575168\n",
      "Accuracy: 0.999, Error:0.014169046566166153\n",
      "Accuracy: 0.999, Error:0.01400494798149157\n",
      "Accuracy: 0.999, Error:0.013972760615272806\n",
      "Accuracy: 0.999, Error:0.013050459960207261\n",
      "Accuracy: 0.999, Error:0.013944860398032584\n",
      "Accuracy: 0.999, Error:0.012765920255116343\n",
      "Accuracy: 0.999, Error:0.012732695948314788\n",
      "Accuracy: 0.999, Error:0.013193294339195952\n",
      "Accuracy: 0.999, Error:0.012206243196458305\n",
      "Accuracy: 0.999, Error:0.012606800821754537\n",
      "Accuracy: 0.999, Error:0.01213395569252461\n",
      "Accuracy: 0.999, Error:0.011834291256409488\n",
      "Accuracy: 0.999, Error:0.01219013590207725\n",
      "Accuracy: 0.999, Error:0.01103383415354144\n",
      "Accuracy: 0.999, Error:0.010939257948999047\n",
      "Accuracy: 0.999, Error:0.010910018700732865\n",
      "Accuracy: 0.999, Error:0.011047238491882386\n",
      "Accuracy: 0.999, Error:0.010438970009958717\n",
      "Accuracy: 0.999, Error:0.010220852997670738\n",
      "Accuracy: 0.999, Error:0.010094740972940637\n",
      "Accuracy: 0.999, Error:0.00996115925126409\n",
      "Accuracy: 0.999, Error:0.009351239136054445\n",
      "Accuracy: 0.999, Error:0.009410025751252368\n",
      "Accuracy: 0.999, Error:0.008964815701389205\n",
      "Accuracy: 0.999, Error:0.008746928763323872\n",
      "Accuracy: 0.999, Error:0.009279018953785167\n",
      "Accuracy: 0.999, Error:0.008115182620106225\n",
      "Accuracy: 0.999, Error:0.008109659129092785\n",
      "Accuracy: 0.999, Error:0.007836588630422676\n",
      "Accuracy: 0.999, Error:0.0077207047816861525\n",
      "Accuracy: 0.999, Error:0.0075526486529734795\n"
     ]
    }
   ],
   "source": [
    "# Initialise the weights:\n",
    "weights_0_1 = 0.2 * np.random.random((input_layer_size, hidden_layer_size)) - 0.1 # (784 x 100)\n",
    "weights_1_2 = 0.2 * np.random.random((hidden_layer_size, output_layer_size)) - 0.1 # (100 x 10)\n",
    "\n",
    "# Train the network:\n",
    "for epoch in range(epochs):\n",
    "    error, correct_cnt = (0,0)\n",
    "    for i in range(1000):\n",
    "        layer_0 = training_data_norm[i: i+1]\n",
    "        label = training_labels[i: i+1]\n",
    "        \n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1)) # (1x100)\n",
    "        layer_2 = np.dot(layer_1, weights_1_2) # (1 x 10)\n",
    "        \n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(label))\n",
    "        error = np.sum((label - layer_2)**2)\n",
    "        \n",
    "        delta_2 = layer_2 - label # (1 x 10)\n",
    "        delta_1 = delta_2.dot(weights_1_2.T) * relu_deriv(layer_1) #(1x100)\n",
    "        \n",
    "        weights_1_2 -= alpha * layer_1.T.dot(delta_2)\n",
    "        weights_0_1 -= alpha * layer_0.T.dot(delta_1)\n",
    "        \n",
    "    print(\"Accuracy: {}, Error:{}\".format(correct_cnt/1000, error))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that just after 60 iterations, our network has trained so well that it correctly classified 99.9% of the training data! But how does it perform on unseen data? Lets use our trained weights in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.845\n"
     ]
    }
   ],
   "source": [
    "correct_test_cnt = 0\n",
    "for i in range(10000):\n",
    "    layer_0 = test_data_norm[i: i + 1]\n",
    "    label = test_labels[i: i + 1]\n",
    "    \n",
    "    layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "    layer_2 = np.dot(layer_1, weights_1_2)\n",
    "    \n",
    "    correct_test_cnt += int(np.argmax(layer_2) == np.argmax(label))\n",
    "\n",
    "print(\"Test Accuracy: {}\".format(correct_test_cnt/10000))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
